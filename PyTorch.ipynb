{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbf6577",
   "metadata": {},
   "source": [
    "# PyTorch Tutorials 2.0\n",
    "07/05/2023 <br>\n",
    "This notebook is created for going through the offical [PyTorch Tutorials](https://pytorch.org/tutorials/beginner/basics/intro.html#learn-the-basics) to help readers get familiar with the latest PyTorch.\n",
    "\n",
    "\n",
    "Content:\n",
    "1. [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html#tensors)\n",
    "2. [Datasets and DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#datasets-dataloaders)\n",
    "3. [Build Model](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html#build-the-neural-network)\n",
    "4. [Automatic Differentiation](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#automatic-differentiation-with-torch-autograd) & [Optimization Loop](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#automatic-differentiation-with-torch-autograd)\n",
    "5. [Save, Load and Use Model](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html#save-and-load-the-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5b9be",
   "metadata": {},
   "source": [
    "## [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html#tensors)\n",
    "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
    "\n",
    "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data. Tensors are also optimized for automatic differentiation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97d61d",
   "metadata": {},
   "source": [
    "In a nutshell, tensors are the basic blocks to build models using PyTorch.\n",
    "The input data needs to be in the tensors format, and the parameters of models will be tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08c68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #PyTorch package\n",
    "import numpy as np #NumPy package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae28190",
   "metadata": {},
   "source": [
    "### list to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39df327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]] \n",
    "tensor_data=torch.tensor(data) #we can convert a list into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69216bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6180e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [[1, 2],[3, 4],[1]]  \n",
    "# tensor_data=torch.tensor(data) #the data has to be in a well defined matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a31442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1,2]  \n",
    "tensor_data=torch.tensor(data)\n",
    "tensor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f65b048",
   "metadata": {},
   "source": [
    "### numpy array to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f837561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array([[1, 2],[3, 4]])\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ac8a7",
   "metadata": {},
   "source": [
    "### create tensors from another tensors (based on its shape & datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80201d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481b7216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4807, 0.2131],\n",
       "        [0.2904, 0.0420]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(x_np, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b6799",
   "metadata": {},
   "source": [
    "### create tensors based on shape info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e60004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1027, 0.0010, 0.1098],\n",
       "        [0.3816, 0.1311, 0.9208]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "torch.rand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a72f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7a675f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01075a",
   "metadata": {},
   "source": [
    "### attributes of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec40ef80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af24464",
   "metadata": {},
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a2c95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9af15",
   "metadata": {},
   "source": [
    "data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3045f5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe37c7",
   "metadata": {},
   "source": [
    "device tensor is stored on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43fc4361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49252a8",
   "metadata": {},
   "source": [
    "### operations on tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d6cf6",
   "metadata": {},
   "source": [
    "move to other device if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afdf4179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu' #or 'cuda' if GPUs are available\n",
    "x_np.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c872d71",
   "metadata": {},
   "source": [
    "check if a device is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16d06d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50888852",
   "metadata": {},
   "source": [
    "### indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30681d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f'Input tensors:\\n{tensor}')\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[:, -1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594fc99",
   "metadata": {},
   "source": [
    "### modify the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e192d8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor[:,1] = 0 #change the second column to a zero column\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7758f30f",
   "metadata": {},
   "source": [
    "### concatenation* (important operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec7f93",
   "metadata": {},
   "source": [
    "concatenate by rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6186201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([tensor, tensor, tensor], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee006a",
   "metadata": {},
   "source": [
    "concatenate by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4cefb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([tensor, tensor, tensor], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe97523",
   "metadata": {},
   "source": [
    "### arithmetic operations* (important operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86701ceb",
   "metadata": {},
   "source": [
    "#### transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efa778d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors:\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "Transposed tensors:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(f'Input tensors:\\n{tensor}')\n",
    "print(f'Transposed tensors:\\n{tensor.T}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b747ea",
   "metadata": {},
   "source": [
    "#### element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fcc47d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 2., 2.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [2., 1., 2., 2.],\n",
       "        [2., 1., 2., 2.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor+tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "996d62ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "608a0ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.mul(tensor.T) # = tensor*tensor.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef5120",
   "metadata": {},
   "source": [
    "#### matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d7b0fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors:\n",
      "tensor([[0.9151, 0.4169, 0.7529, 0.3129],\n",
      "        [0.5968, 0.6585, 0.7329, 0.8763],\n",
      "        [0.1691, 0.8825, 0.9527, 0.9169]])\n",
      "tensor([[0.5196, 0.5374],\n",
      "        [0.3964, 0.2188],\n",
      "        [0.3953, 0.5543],\n",
      "        [0.4013, 0.6413]])\n",
      "\n",
      "Matrix multiplication:\n",
      "tensor([[1.0639, 1.2011],\n",
      "        [1.2124, 1.4330],\n",
      "        [1.1822, 1.4000]])\n"
     ]
    }
   ],
   "source": [
    "tensor1,tensor2=torch.rand((3,4)),torch.rand((4,2))\n",
    "print(f'Input tensors:\\n{tensor1}\\n{tensor2}')\n",
    "print(f'\\nMatrix multiplication:\\n{tensor1.matmul(tensor2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0ea4d1",
   "metadata": {},
   "source": [
    "#### dot product/scalar product/inner product (vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cf58114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8564, 0.0744, 0.4400]), tensor([0.4661, 0.2564, 0.3391]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1,v2=torch.rand((3)),torch.rand((3))\n",
    "v1,v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47000019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5674)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7100f",
   "metadata": {},
   "source": [
    "#### row/column-wise sum/mean/std/min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04ae1bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors:\n",
      "tensor([[0.9151, 0.4169, 0.7529, 0.3129],\n",
      "        [0.5968, 0.6585, 0.7329, 0.8763],\n",
      "        [0.1691, 0.8825, 0.9527, 0.9169]])\n",
      "\n",
      "row-wise sum:\n",
      "tensor([2.3979, 2.8644, 2.9212])\n",
      "\n",
      "row-wise mean:\n",
      "tensor([0.5995, 0.7161, 0.7303])\n",
      "\n",
      "column-wise std:\n",
      "tensor([0.3744, 0.2328, 0.1215, 0.3376])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Input tensors:\\n{tensor1}\\n')\n",
    "\n",
    "print(f'row-wise sum:\\n{tensor1.sum(dim=1)}\\n')\n",
    "\n",
    "print(f'row-wise mean:\\n{tensor1.mean(dim=1)}\\n')\n",
    "\n",
    "print(f'column-wise std:\\n{tensor1.std(dim=0)}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10211f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row-wise min:\n",
      "torch.return_types.min(\n",
      "values=tensor([0.3129, 0.5968, 0.1691]),\n",
      "indices=tensor([3, 0, 0]))\n",
      "\n",
      "column-wise max:\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9151, 0.8825, 0.9527, 0.9169]),\n",
      "indices=tensor([0, 2, 2, 2]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'row-wise min:\\n{tensor1.min(dim=1)}\\n')\n",
    "\n",
    "print(f'column-wise max:\\n{tensor1.max(dim=0)}\\n')\n",
    "\n",
    "# note that the min/max operations not only return the min/max, it also returns the ordered index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f278c",
   "metadata": {},
   "source": [
    "#### aggregating all values of a tensor into one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46520fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9151, 0.4169, 0.7529, 0.3129],\n",
       "        [0.5968, 0.6585, 0.7329, 0.8763],\n",
       "        [0.1691, 0.8825, 0.9527, 0.9169]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fd31419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1835)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd7b1ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6820)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fc7a36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2604)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0607ca07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1691)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af5a9a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9527)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ac21f",
   "metadata": {},
   "source": [
    "## [Datasets & Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#datasets-dataloaders)\n",
    "\n",
    "Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "The primary purpose of 'DataLoader' is to facilitate efficient data loading and preprocessing. For example, the DataLoader provides an iterable interface, allowing you to load and process data in a streaming fashion rather than loading the entire dataset into memory all at once. This is particularly useful when working with datasets that are too large to fit in memory. The data loader fetches data on-the-fly as needed, reducing the memory footprint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba2648",
   "metadata": {},
   "source": [
    "### load your own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d10b7f",
   "metadata": {},
   "source": [
    "I used a [public](https://github.com/Sutanoy/Public-Regression-Datasets/blob/main/Bank_Marketing.csv) data to demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62430ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path,features,target,delimiter=';'):\n",
    "        self.data = pd.read_csv(file_path,delimiter=';')\n",
    "        self.X=self.data[features]\n",
    "        self.y=self.data[target].replace(('yes', 'no'), (1, 0)) #converted the binary category to 0 and 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.tolist()\n",
    "        return torch.from_numpy(self.X.iloc[idx].values).type(torch.float), torch.from_numpy(self.y.iloc[idx].values).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d50b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['age', 'balance', 'day','duration', 'pdays','previous'] #picked some numerical features\n",
    "target=['y']\n",
    "dataset=CustomDataset(file_path='./Bank_Marketing.csv',features=features,target=target,delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d921730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36168, 9043)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1356cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23cff6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "batch_size=64\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcc72b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abfbcb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 6])\n",
      "Labels batch shape: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a486c",
   "metadata": {},
   "source": [
    "<b>note</b>: in the custom dataset function, we did a simple data conversion on the target \"y\", and when we define the dataset, we only selected numerical features; in reality, your dataset might have all kinds of features, and you will need to preprocess (one-hot encoding | embedding) the data so everything is either a float or int."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcaef2d",
   "metadata": {},
   "source": [
    "# [Build Model](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html#build-the-neural-network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9e9a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4ee99",
   "metadata": {},
   "source": [
    "The template of the model looks as follow:<br>\n",
    "$class ClassName(nn.Module):\n",
    "    def __init__(self,inputDim,outputDim):\n",
    "        super().__init__()\n",
    "        ##define components of your model\n",
    "    def forward(self, x):\n",
    "        ##show how the input flow through the model using the components defined above\n",
    "        return y\n",
    "     $\n",
    "\n",
    "I used three examples to show how to use the template:\n",
    "1. linear regression\n",
    "2. logistic regression\n",
    "3. a simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc9b76",
   "metadata": {},
   "source": [
    "## linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7148082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self,inputDim,outputDim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(inputDim, outputDim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y=self.linear(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d9a546",
   "metadata": {},
   "source": [
    "[Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) function applies a linear transformation to the incoming data: y=Ax+b<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "932b1a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61e2551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(\n",
      "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "LinearRegressionModel = LinearRegression(inputDim=6,outputDim=1).to(device)\n",
    "print(LinearRegressionModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0ea3dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7313, 0.5935, 0.2909, 0.3071, 0.4727, 0.1642]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(1, 6, device=device)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cf0a351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1848]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegressionModel(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1bc95a",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99ceb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self,inputDim,outputDim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(inputDim, outputDim)\n",
    "        self.lastLayer=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.linear(x)\n",
    "        y = self.lastLayer(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d26dc0",
   "metadata": {},
   "source": [
    "[Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid) applies the element-wise sigmoid function.\n",
    "<br>\n",
    "Since we first made a linear transformation, and then applied that into the sigmoid function, the model becomes a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1166683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
      "  (lastLayer): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "LogisticRegressionModel = LogisticRegression(inputDim=6,outputDim=1).to(device)\n",
    "print(LogisticRegressionModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df4d52f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6701]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegressionModel(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e4cfb",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9df55c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self,inputDim,outputDim):\n",
    "        super().__init__()\n",
    "        self.structure = nn.Sequential(\n",
    "            nn.Linear(inputDim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, outputDim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.structure(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0be77",
   "metadata": {},
   "source": [
    "[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) is an ordered container of modules. The data is passed through all the modules in the same order as defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "637df098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (structure): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=4, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "SimpleNNModel = SimpleNN(inputDim=6,outputDim=1).to(device)\n",
    "print(SimpleNNModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1d71d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4196]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleNNModel(X) #note that they sum up to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89c4e0",
   "metadata": {},
   "source": [
    "[here](https://pytorch.org/docs/stable/nn.html) is the full list of functions you can use to build your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49446ef",
   "metadata": {},
   "source": [
    "##  [Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#automatic-differentiation-with-torch-autograd) & [Optimization](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#optimizing-model-parameters)(training)\n",
    "\n",
    "All the model defined is a initialized model, and their parameters are randomly initialized, although it does give us a prediction, but the parameters are not optimized based on the training data. <br>\n",
    "\n",
    "To optimize the parameters in ways that the model will learn from the data, we typically use gradient of the loss function to adjust the parameters.\n",
    "\n",
    "To compute those gradients, PyTorch has a built-in differentiation engine called torch.autograd. It supports automatic computation of gradient for any computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3dc8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss, current = loss.item(), (batch + 1) * len(X)\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "def test_loop(dataloader, model, loss_fn, threshold=0.5):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            yhat=(pred >= threshold).long()\n",
    "            correct += (yhat == y).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564ab77",
   "metadata": {},
   "source": [
    "### binary classification: loss function = Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d7026eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the dataloader\n",
    "features=['age', 'balance', 'day','duration', 'pdays','previous'] #picked some numerical features\n",
    "target=['y']\n",
    "\n",
    "dataset=CustomDataset(file_path='./Bank_Marketing.csv',features=features,target=target,delimiter=';')\n",
    "\n",
    "train_size = int(0.75 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "trainset, testset = random_split(dataset, [train_size, test_size])\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "inputs, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e613f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the model\n",
    "SimpleNNModel = SimpleNN(inputDim=6,outputDim=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317dc8c2",
   "metadata": {},
   "source": [
    "after `pip install tensorboard` <br>\n",
    "you can use the tensorboard by this command in the ternimal `tensorboard --logdir=runs`      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b35bd4",
   "metadata": {},
   "source": [
    "#### visualize your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "addcaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./runs/')\n",
    "writer.add_graph(model=SimpleNNModel,input_to_model=inputs)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25f93151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 7.607918  [   64/33908]\n",
      "loss: 0.919494  [ 6464/33908]\n",
      "loss: 0.502805  [12864/33908]\n",
      "loss: 0.508079  [19264/33908]\n",
      "loss: 0.421540  [25664/33908]\n",
      "loss: 0.476836  [32064/33908]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.419637 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.426845  [   64/33908]\n",
      "loss: 0.273120  [ 6464/33908]\n",
      "loss: 0.372531  [12864/33908]\n",
      "loss: 0.352171  [19264/33908]\n",
      "loss: 0.343127  [25664/33908]\n",
      "loss: 0.344391  [32064/33908]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.391770 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.392212  [   64/33908]\n",
      "loss: 0.379488  [ 6464/33908]\n",
      "loss: 0.533383  [12864/33908]\n",
      "loss: 0.389350  [19264/33908]\n",
      "loss: 0.330368  [25664/33908]\n",
      "loss: 0.373036  [32064/33908]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.361651 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.396607  [   64/33908]\n",
      "loss: 0.387730  [ 6464/33908]\n",
      "loss: 0.391032  [12864/33908]\n",
      "loss: 0.223836  [19264/33908]\n",
      "loss: 0.430041  [25664/33908]\n",
      "loss: 0.319769  [32064/33908]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.358355 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.480702  [   64/33908]\n",
      "loss: 0.275291  [ 6464/33908]\n",
      "loss: 0.255326  [12864/33908]\n",
      "loss: 0.292762  [19264/33908]\n",
      "loss: 0.386602  [25664/33908]\n",
      "loss: 0.315042  [32064/33908]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340805 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(SimpleNNModel.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, SimpleNNModel, loss_fn, optimizer)\n",
    "    test_loop(testloader, SimpleNNModel, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f55f9",
   "metadata": {},
   "source": [
    "## [save and load model](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html#save-and-load-the-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c07b5c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (structure): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=4, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleNNModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f99857c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(SimpleNNModel, 'SimpleNNModel_demo_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a9da4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340805 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(testloader, SimpleNNModel, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b109f2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 18.8%, Avg loss: 39.887017 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SimpleNNModel = SimpleNN(inputDim=6,outputDim=1).to(device)\n",
    "test_loop(testloader, SimpleNNModel, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0daec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340805 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SimpleNNModel=torch.load('SimpleNNModel_demo_weights')\n",
    "test_loop(testloader, SimpleNNModel, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f633f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
